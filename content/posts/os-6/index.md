+++
date = '2025-05-26T10:33:12+08:00'
draft = true
title = '第六章 并发程序设计'
summary = "操作系统笔记"
tags = ["笔记", "OS", "操作系统"]
categories = ["StudyBase"]
seriesOpened = true
series = ["笔记-操作系统"]
series_order = 6
+++

{{< katex >}} 

## Part1 并发进程

### 1.1 顺序程序设计、并发程序设计

#### 顺序程序设计

在传统的顺序程序设计中，程序被看作是一系列有序执行的操作或指令，这些操作按照既定的顺序依次在处理器上执行。这种顺序性体现在两个方面：

- 内部顺序性：每个程序在处理器上的执行是严格有序的
- 外部顺序性：设计程序时，把一个具体的问题的求解过程设计成一个程序、或严格顺序执行的程序序列

顺序程序设计的特性
- 程序执行的顺序性：程序指令执行是严格按序的
- 计算环境的封闭性：程序运行时如同独占受操作系统保护的资源
- 计算结果的确定性：程序执行结果与执行速度和执行时段无关
- 计算过程的可再现性：程序对相同数据集的执行轨迹是确定的

然而，随着多道程序设计技术的发展，操作系统**允许多个程序同时进入内存，并通过资源的合理分配和调度，让它们能够并发地争用处理器的运行机会**。这种情况下，系统中可以同时存在多个正在运行的进程，它们在宏观上表现为并发执行。

尽管如此，os 依然需要能够保证按照顺序程序设计思想编写的程序在并发环境下的正确性，使得**每个进程都像是在独占计算机资源一样运行，不会受到其他进程的干扰**——这类进程之间没有直接的相互影响，属于无关的并发进程。并发程序设计正是在这种背景下提出的，它要求程序员在设计程序时，既要**考虑顺序执行的逻辑**，又要**兼顾并发执行时可能出现的资源竞争和同步问题**，从而保证程序在多进程环境下的正确性和高效性。

#### 并发程序设计

进程的并发性(Concurrency)是指一组进程的执行在时间上是重叠的。举例来说，假设有两个进程A(a1、a2、a3)，B(b1、b2、b3)。如果系统允许进程交叉执行，比如执行顺序可以是a1，b1，a2，b2，a3，b3，也可以是a1，a2，b1，b2，b3，a3，这就说明进程A和B的执行是并发的。

从宏观角度来看，并发性意味着在一个时间段内，多个进程都处于运行或等待运行的状态，仿佛它们都在同一个处理器上同时运行；但从微观角度来看，实际上在任一时刻只有一个进程真正占用处理器执行，其余进程则处于等待状态。

并发程序设计的核心思想，是**将一个程序划分为若干个可以同时执行的程序模块，每个模块与其处理的数据共同组成一个进程**。这些进程之间可以并发执行，但**往往存在某种制约关系**。为了解决进程之间的协调与同步，常常需要借助通信机制，比如通过`send`和`receive`操作实现进程间的信息交换和协作。

对一个程序`WHILE (TRUE) {input, process, output}`顺序执行会导致`input`要等后两个操作完成后才开始，浪费时间，系统效率很低；这时候把程序分成三个部分

- i: `WHILE (TRUE) {input, send}`
- p: `WHILE (TRUE) {receive, process, send}`
- o: `WHILE (TRUE) {receive, output}`

![](ipo_concurrency.png)

并发程序设计具有以下几个显著特性。

1. 并行性：即多个进程可以在多道程序系统中并发执行，或者在多处理器系统中实现真正的并行执行，这大大提高了计算效率。
2. 共享性：多个进程可以共享系统中的软件资源，比如共享内存、文件等。
3. 交往性：多个进程在并发执行时不可避免地会产生相互制约和协作的关系，这也使得并发程序的设计和实现比顺序程序更加复杂和具有挑战性。

### 1.3 并发进程的制约关系

在并发程序设计中，并发进程可以分为无关的并发进程和交往的并发进程。

#### 无关的并发进程

一组进程分别在不同的变量集合上运行，它们之间没有共享变量，一个进程的执行不会影响其他进程的结果。只要满足这种无关性，进程的执行顺序与时间无关，这种条件也被称为**Bernstein条件**。具体来说，设程序\\(p1\\)和\\(p2\\)分别引用的变量集为\\(R(p1)\\)、\\(R(p2)\\)，改变的变量集为\\(W(p1)\\)、\\(W(p2)\\)，如果满足$$ (R(p1)∩W(p2))∪(R(p2)∩W(p1))∪(W(p1)∩W(p2))= \varnothing $$那么这两个进程的执行就是无关的。

举例：四个进程 S1~S4 中的四条语句
```c
a = x + y // S1
b = z + 1 // S2
c = a - b // S3
w = c + 1 // S4
```
计算得知 S1 和 S2 满足Bernstein条件，是无关的并发进程；其余的均不满足，是交往的并发进程，并发执行时，可能会产生**和时间有关的错误**。

#### 交往的并发进程

交往的并发进程是指**一组进程共享某些变量，一个进程的执行可能会影响其他进程的结果**。这种情况下，进程之间存在直接或间接的制约关系，程序的执行结果与进程的相对执行速度和调度顺序密切相关。如果程序设计不当，交往的并发进程可能会出现**与时间有关的错误**，比如结果错误、进程永远等待等问题。

##### 与时间有关的错误：结果错误

售票的代码：

```c
void T() {
  // 按照旅客要求找到储存余票数量的变量A
  int x = A;
  if (x >= 1){
    x1--;
    A = x;
    // 输出票
  } else {
    // 提示票售完
  }
}
```

![](ticket_selling.png)
图中用红线和虚线箭头表示进程切换。假设此时 Aj 的初始值为1，那么 T1 和 T2 读取到的 X1 和 X2 都是1，两个线程的判断条件都成立，于是它们都进入 if 分支，各自将 X1 和 X2 减1（变为0），然后分别把0写回 Aj。最终，两张票都被“成功”售出，输出了两次“出票”信息。

##### 与时间有关的错误：永远等待

由于`borrow`和`return`共享代表主存物理资源的临界变量X，对并发执行不加限制会导致错误。

![](memo.png)

在这段代码中，`borrow(int B)`函数用于申请主存资源，`return(int B)`函数用于归还主存资源。主存总量为`memory`，当前可用主存为`X`。

1. 某进程P1调用`borrow(B)`，执行到`while(B > X)`，发现B大于当前可用主存X，于是**本应进入等待主存资源队列**（图中⑤），但此时P1还没有真正进入等待队列。
2. 就在P1即将进入等待队列之前，另一个进程P2调用了`return(B)`，归还了主存资源。P2在归还时，执行了`X = X + B`，并尝试“释放等主存资源进程”（图中④），但此时**等待队列里还没有P1**，所以没有进程被唤醒。
3. 之后，P1才真正进入等待队列（图中⑤），但此时P2已经归还完主存并离开，等待队列里只有P1自己。
4. 如果此后没有其他进程再归还主存资源，P1就会永远等待，因为**它进入等待队列时，错过了刚刚归还的主存资源的唤醒机会**。

#### 进程的交互：竞争与协作

##### 竞争——互斥

竞争关系是指多个进程争夺同一资源。资源竞争带来了两个经典问题：死锁和饥饿。

死锁是指一组进程因争夺资源而陷入永远等待的状态，**每个进程都持有部分资源并等待其他进程释放资源，最终所有进程都无法继续执行**。

![](dead_lock.png)

> ⬆️举一个典型的死锁例子：假设系统中有一台打印机和一台磁带机，进程 P 和进程 Q 都需要使用这两台设备。进程 P 先申请并获得了打印机，随后进程切换到 Q，Q 申请磁带机，再切换回 P。随后，P 在申请磁带机时被阻塞，因为此时磁带机已经被进程 Q 占用，而 Q 在申请打印机时也被阻塞，因为打印机已经被进程 P 占用。这样，两个进程都在等待对方释放自己需要的设备，形成了死锁，系统无法继续推进。

饥饿则是指**某个进程由于其他进程总是优先于它而被无限期拖延，迟迟得不到所需资源**。

为了解决竞争引起的问题，提出了**互斥(mutual exclusion, mutex)**。互斥是指当多个进程需要访问同一临界资源时，任何时刻最多只允许一个进程访问该资源，其他进程必须等待，直到资源被释放。

###### 协作——同步

协作关系则是指多个进程为完成同一任务需要分工协作，它们之间需要在某些点上进行协调和通信。由于合作的每一个进程都是独立地以不可预知的速度推进，协作进程需要在特定的同步点等待彼此的信号或消息。合作进程到达同步点时，可能需要阻塞自己，等待其他进程的信号或消息。

同步(Synchronization)则是指两个或多个进程基于某种条件协调各自的活动，一个进程的执行依赖于另一个进程的消息或信号，只有在收到信号后才能继续执行。

实际上，**进程互斥关系是一种特殊的同步关系，是对进程使用共享资源次序上的一种协调**。

## Part2 临界区管理

### 2.1 临界区

在并发程序设计中，**临界资源**是指一次只允许一个进程访问的共享资源，也就是互斥共享变量所代表的资源。例如，某个全局变量、缓冲区、打印机等都可以作为临界资源。由于多个进程可能同时访问这些资源，若不加以限制，就会出现数据不一致或系统错误。

**临界区**（Critical Section）是指并发进程中访问临界资源的那段程序代码——每个进程在执行过程中，只有在进入自己的临界区时，才会访问和操作临界资源，临界区之外的代码则不涉及对临界资源的访问。

多个并发进程访问临界资源时存在竞争制约关系，如果两个进程同时停留在相关的临界区内，就会出现与时间相关的错误。

#### 临界区的描述

- `shared <variable>`: 明确哪些变量或资源是临界资源
- `region <variable> do <statement_list>`: 确定哪些代码段是临界区
  
- 如果两个进程的临界区访问同一个临界资源，这两个临界区就是**相关的临界区**，它们之间必须互斥进入。
- 如果两个临界区访问的临界资源互不相关，则它们可以同时进入，无需互斥。

#### 临界区管理的三大基本要求

为了保证系统的正确性和效率，临界区的管理必须满足以下三个基本要求：

1. Mutual Exclusion：任何时刻，至多只允许一个进程进入相关的临界区。即如果有一个进程在临界区内，其他进程必须等待，直到该进程离开临界区。
2. Bounded Waiting：每个进程在发出进入临界区的请求后、请求被允许前，最多只能有有限个其他进程进入临界区，防止某个进程无限期等待（即无饥饿）。
3. Progress：如果当前没有任何进程在它的临界区内执行，并且有一些进程希望进入它们的临界区，那么只有那些没有在它们的剩余区（remainder section，剩余区是进程的临界区中尚未执行的部分）执行的进程，才有资格参与决定下一个进入临界区的进程是谁，并且这种选择不能被无限期地推迟。
4. 一个进程在临界区内不能无限停留，必须在有限时间内退出临界区。

#### 临界区的错误实现

假设进程进入的代码如下：

```c
bool inside1 = false; // 起初，不在互斥区
void process1() {
  // ...
  // 进入互斥区
  while(inside2 || inside3 || ...);     // 如果竞争进程进入了互斥区，则等待
  inside1 = true;     // 锁定
  // 互斥区的代码……
  inside1 = false;    // 解锁
}
```

只从顺序逻辑来看这时合理的，但是别忘了并发进程可以在任何时候切出当前进程，再切入另一个进程，这样的代码会导致如下图的问题：

![](wrong.png)

如果代码执行顺序是1->3->4->2，那么进程1和进程2会同时进入临界区，导致数据不一致。

![](wrong2.png)

这也是错的，如果代码执行顺序是1->2->3->4，那么进程1和进程2会同时被阻塞。

#### 临界区的正确实现：Peterson算法

```c
bool inside[2] = {false, false};    // 起初，不在互斥区
enum {0, 1} turn;                   // 让权变量：被谦让的进程

void p0() {
  inside[0] = true;
  turn = 1;
  while(inside[1] && turn == 1);
  // 互斥区的代码……
  inside[0] = false;
}

void p1() {
  inside[1] = true;
  turn = 0;
  while(inside[0] && turn == 0);
  // 互斥区的代码……
  inside[1] = false;
}
```

> “让权”，指把进入临界区的权利让给对方。

##### 理解1：怎么判断这个算法谁能进？

算法的意思是，使用`inside`变量表示“意愿声明”，`turn`则是“让权变量”，当对方想进、并且自己让权时，对方才能进入。

来看看这个算法会不会错：

![](right.png)
> 忽略又乱又丑的箭头

- 如果执行顺序是 1、2、4、5、6，双方都想进、都让权，但是最后进行让权的是 p1, 所以 p0 先进（6不停循环直到进程切换到3, while 判断为 false，1 进入）
- 如果执行顺序是 1、4、5、6, 双方都想进、p1 让权，~~最终结果就肯定是 p0~~ 不对！仔细逐个语句分析：p1 让权后不停循环、直到切换到 p0, p0 在 2 处又进行了一次让权。由于两个进程都只有一次让权机会，最后让权的是 p0, 那对面的 p1 就占了便宜，p1 会先进入临界区。

##### 理解2：为什么这个算法能保证互斥？

~~我不道啊~~ 这个算法之所以能保证互斥，是因为`turn`这个变量**只能有一个值**，这就意味着，两个进程不可能同时满足`while`条件为假，只有一方能进入临界区，另一方必须等待对方退出并将自己的`inside`标记为`false`后，才能进入。

{{< alert icon="scope" cardColor="#80CDBF" textColor="#000000" >}}

##### 扩展成多个进程

Peterson 算法本身是为两个进程互斥设计的。如果要扩展到多个（n个）进程互斥，可以采用它的多进程扩展版本，最著名的就是Peterson’s n进程算法，也叫过滤锁（Filter Lock）或Peterson’s generalization。

扩展的基本思想是：让每个进程依次通过多个“关卡”，每一关都像两人Peterson算法那样和其他进程竞争，只有通过所有关卡的进程才能进入临界区。每一关都保证：如果有多个进程竞争，只有一个能通过，其他必须等待。

```c
int level[n];      // 每个进程当前到达的关卡
int last[n];       // 每一关最后到达的进程编号

// 进程i的入口协议

process(int i) {
  for (int k = 1; k < n; k++) {
      level[i] = k;
      last[k] = i;
      // 等待，直到没有其他进程在同一关或更高关，并且自己不是最后到达的
      while (exists j ≠ i such that level[j] >= k && last[k] == i);
  }
  // 进入临界区
  // 临界区代码……
  // 离开临界区
  level[i] = 0;
}
```

{{</alert>}}

### 2.3 临界区管理：硬件支持

TS 和 SWAP 两个指令通过让操作原子化来避免前面提到过的进程切换问题。

#### 关中断：实现互斥最简单的方法

关中断是实现互斥最简单的方法，在进入临界区之前关中断，在退出临界区之后开中断。

#### 测试并建立（Test-and-Set，测试并置位）指令

![](TS_inst.png)

左边的代码是TS指令的处理过程。`TS(bool &x)` 是一个原子操作（即不可分割的操作），它的作用是：如果变量`x`为`true`，就把`x`置为`false`并返回`true`；如果`x`为`false`，就直接返回`false`。这个操作保证了在多进程/多线程环境下，只有一个进程能通过`TS`指令成功把`x`从`true`变成`false`并得到`true`，其他进程只能得到`false`。

右边的代码展示了如何用TS指令实现n个进程的互斥。首先，定义一个共享的布尔变量`s`，初值为`true`，表示“锁是开的”。每个进程`Pi`在进入临界区前，都会执行`while(!TS(s));`，也就是不断尝试用TS指令“上锁”。只有当`s`为`true`时，TS才会返回`true`，进程才能跳出循环进入临界区，并且此时`s`已被置为`false`，其他进程再调用TS时只能得到`false`，只能继续等待。这样就保证了同一时刻只有一个进程能进入临界区，实现了互斥。临界区执行完后，进程将`s`重新置为`true`，相当于“开锁”，允许其他进程进入临界区。

#### 对换指令

![](swap_inst.png)

左边的代码定义了SWAP指令的处理过程。`SWAP(bool &a, bool &b)` 是一个原子操作，它的作用是交换变量`a`和`b`的值。这个操作保证了在多进程/多线程环境下，两个变量的值交换是不会被其他进程打断的。

右边的代码展示了如何用SWAP指令实现n个进程的互斥。首先，定义一个共享的布尔变量`lock`，初值为`false`，表示“锁是开的”。每个进程`Pi`在进入临界区前，先定义一个局部变量`keyi`，初值为`true`。然后进程进入一个`do-while`循环，不断执行`SWAP(keyi, lock)`。只有当`lock`为`false`时，`while(keyi)`条件为假，进程跳出循环进入临界区。其他进程如果此时尝试SWAP，由于`lock`已经是`true`，它们的`keyi`会变成`true`，`lock`还是`true`，`while(keyi)`条件为真，只能继续等待。

这样就保证了同一时刻只有一个进程能进入临界区，实现了互斥。临界区执行完后，进程再次执行`SWAP(keyi, lock)`，此时`keyi`为`false`，`lock`为`true`，交换后`lock`变为`false`，释放锁，允许其他进程进入临界区。

#### 总结

TS（Test-and-Set）和SWAP等原子指令虽然能实现多处理器下的互斥，但属于忙等待（自旋锁），即等待进程会不断占用CPU轮询，效率较低，适合临界区极短、竞争不激烈的场景。

临界区代码应尽量短小精悍，减少锁的持有时间，提高系统并发度。

关中断适合内核态、单处理器、临界区极短的场合，不能滥用。

TS、SWAP等硬件原子指令适合实现基本的互斥机制，但忙等待效率低，适用范围有限。

现代操作系统更倾向于用信号量、互斥锁等高级同步机制，结合硬件原语和调度机制，避免忙等待和系统响应降低。

### 6.3 PV 操作

### 3.1 问题背景
